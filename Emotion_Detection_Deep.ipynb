{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishant\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "C:\\Users\\Nishant\\CourseraAnaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from urllib import urlretrieve\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import theano\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainingSet = '.\\\\data\\\\fer2013.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loading the data and splitting into training and test set\n",
    "df = read_csv(os.path.expanduser(TrainingSet))\n",
    "df['pixels'] = df['pixels'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "output_label = np.array(df['emotion'].values)\n",
    "features_image = np.vstack(df['pixels'].values)  # scale pixel values to [0, 1]\n",
    "features_image = features_image.astype(np.float32)\n",
    "x_train = features_image[:30000]\n",
    "y_train = output_label[:30000]\n",
    "x_test = features_image[30000:]\n",
    "y_test = output_label[30000:]\n",
    "x_train = x_train.reshape((-1, 1, 48, 48))\n",
    "x_test = x_test.reshape((-1, 1, 48, 48))\n",
    "y_train = y_train.astype(np.uint8)\n",
    "y_test = y_test.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### DEEP NEURAL NETWORK #######\n",
    "\n",
    "net2 = NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('conv2d3', layers.Conv2DLayer),\n",
    "            ('maxpool3', layers.MaxPool2DLayer),\n",
    "            ('dropout3', layers.DropoutLayer),\n",
    "            ('conv2d4', layers.Conv2DLayer),\n",
    "            ('maxpool4', layers.MaxPool2DLayer),\n",
    "            ('dropout4', layers.DropoutLayer),\n",
    "            ('dense1', layers.DenseLayer),\n",
    "            ('dropout5', layers.DropoutLayer),\n",
    "            ('dense2', layers.DenseLayer),\n",
    "            ('dropout6', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    # input layer\n",
    "    input_shape=(None, 1, 48, 48),\n",
    "    \n",
    "    # layer conv2d1\n",
    "    conv2d1_num_filters=64,\n",
    "    conv2d1_filter_size=(3, 3),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_W=lasagne.init.GlorotUniform(),     \n",
    "    maxpool1_pool_size=(2, 2),    \n",
    "    dropout1_p=0.2,\n",
    "    \n",
    "    # layer conv2d2    \n",
    "    conv2d2_num_filters=128,\n",
    "    conv2d2_filter_size=(3, 3),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify,   \n",
    "    maxpool2_pool_size=(2, 2),\n",
    "    dropout2_p=0.2,\n",
    "    \n",
    "     # layer conv2d3 \n",
    "    conv2d3_num_filters=512,\n",
    "    conv2d3_filter_size=(3, 3),\n",
    "    conv2d3_nonlinearity=lasagne.nonlinearities.rectify,   \n",
    "    maxpool3_pool_size=(2, 2),\n",
    "    dropout3_p=0.2,\n",
    "    \n",
    "    ## layer conv2d4\n",
    "    conv2d4_num_filters=512,\n",
    "    conv2d4_filter_size=(3, 3),\n",
    "    conv2d4_nonlinearity=lasagne.nonlinearities.rectify,   \n",
    "    maxpool4_pool_size=(2, 2),\n",
    "    dropout4_p=0.2,    \n",
    "    \n",
    "    # dense fully connected layer 1\n",
    "    dense1_num_units=256,\n",
    "    dense1_nonlinearity=lasagne.nonlinearities.rectify,   \n",
    "    dropout5_p=0.2,    \n",
    "    \n",
    "    # dense fully connected layer 2\n",
    "    dense2_num_units=512,\n",
    "    dense2_nonlinearity=lasagne.nonlinearities.rectify,   \n",
    "    dropout6_p=0.2,    \n",
    "    \n",
    "    # output Layer\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=7,\n",
    "    \n",
    "    # optimization method params\n",
    "    update=nesterov_momentum,\n",
    "    update_learning_rate=0.005,\n",
    "    update_momentum=0.9,\n",
    "    max_epochs=100,\n",
    "    verbose=1,\n",
    "    )\n",
    "# Train the network\n",
    "deepFacialRecognition = net2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the model for future use\n",
    "with open('.\\\\TrainedModels\\\\Facial_Expression_Deep.pickle', 'wb') as f:\n",
    "    pickle.dump(net2, f, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading features from pre trained model\n",
    "f = open('.\\\\TrainedModels\\\\Facial_Expression_Deep.pickle', 'rb')\n",
    "net2 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if loading is done in non GPU enabled (cuda not installed) then save using below command\n",
    "pvals = [p.get_value() for p in lasagne.layers.get_all_params(net2._output_layer)]\n",
    "f = gzip.open('.\\\\TrainedModels\\\\Facial_Expression_Deep.pickle.gz', 'wb')\n",
    "pickle.dump(pvals, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
