{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishant\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\tensor\\signal\\downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n",
      "C:\\Users\\Nishant\\CourseraAnaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from urllib import urlretrieve\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "import theano\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from lasagne.layers import InputLayer, DenseLayer, batch_norm\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the model fro facial key point detection\n",
    "f = open('.\\\\TrainedModels\\\\key.pickle', 'rb')\n",
    "net2 = pickle.load(f)\n",
    "f.close()\n",
    "# Getting the parameter fro all the conv and fully connected layers\n",
    "prev_mod = net2.get_all_params_values()\n",
    "\n",
    "TrainingSet = '.\\\\data\\\\fer2013.csv'\n",
    "#loading the data and splitting into training and test set\n",
    "df = read_csv(os.path.expanduser(TrainingSet))\n",
    "df['pixels'] = df['pixels'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "output_label = np.array(df['emotion'].values)\n",
    "features_image = np.vstack(df['pixels'].values)  # scale pixel values to [0, 1]\n",
    "features_image = features_image.astype(np.float32)\n",
    "x_train = features_image[:30000]\n",
    "y_train = output_label[:30000]\n",
    "x_test = features_image[30000:]\n",
    "y_test = output_label[30000:]\n",
    "x_train = x_train.reshape((-1, 1, 48, 48))\n",
    "x_test = x_test.reshape((-1, 1, 48, 48))\n",
    "x_flipped = x_train[:, :, :, ::-1]\n",
    "x_train = np.concatenate((x_train, x_flipped), axis = 0)\n",
    "y_train = np.concatenate((y_train, y_train), axis = 0)\n",
    "y_train = y_train.astype(np.uint8)\n",
    "y_test = y_test.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net_fin= NeuralNet(\n",
    "    layers=[('input', layers.InputLayer),\n",
    "            ('conv2d1', layers.Conv2DLayer),\n",
    "            ('maxpool1', layers.MaxPool2DLayer),\n",
    "            ('dropout1', layers.DropoutLayer),\n",
    "            ('conv2d2', layers.Conv2DLayer),\n",
    "            ('maxpool2', layers.MaxPool2DLayer),\n",
    "            ('dropout2', layers.DropoutLayer),\n",
    "            ('conv2d3', layers.Conv2DLayer),\n",
    "            ('maxpool3', layers.MaxPool2DLayer),\n",
    "            ('dropout3', layers.DropoutLayer),\n",
    "            ('conv2d4', layers.Conv2DLayer),\n",
    "            ('maxpool4', layers.MaxPool2DLayer),\n",
    "            ('dropout4', layers.DropoutLayer),\n",
    "            ('dense1', layers.DenseLayer),\n",
    "            ('dropout5', layers.DropoutLayer),\n",
    "            ('dense2', layers.DenseLayer),\n",
    "            ('dropout6', layers.DropoutLayer),\n",
    "            ('output', layers.DenseLayer),\n",
    "            ],\n",
    "    # input layer\n",
    "    input_shape=(None, 1, 48, 48),\n",
    "    \n",
    "    # layer conv2d1\n",
    "    conv2d1_num_filters=64,\n",
    "    conv2d1_filter_size=(3, 3),\n",
    "    conv2d1_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d1_W= np.concatenate(prev_mod['conv1'][0], axis=0).reshape((64, 1, 3, 3)),     \n",
    "    maxpool1_pool_size=(2, 2),    \n",
    "    dropout1_p=0.2,\n",
    "    \n",
    "    # layer conv2d2    \n",
    "    conv2d2_num_filters=128,\n",
    "    conv2d2_filter_size=(3, 3),\n",
    "    conv2d2_nonlinearity=lasagne.nonlinearities.rectify, \n",
    "    conv2d2_W= np.concatenate(prev_mod['conv2'][0], axis=0).reshape((128,64,3,3)),\n",
    "    maxpool2_pool_size=(2, 2),\n",
    "    dropout2_p=0.2,\n",
    "    \n",
    "     # layer conv2d3 \n",
    "    conv2d3_num_filters=512,\n",
    "    conv2d3_filter_size=(3, 3),\n",
    "    conv2d3_nonlinearity=lasagne.nonlinearities.rectify,\n",
    "    conv2d3_W=np.concatenate(prev_mod['conv3'][0], axis=0).reshape((512,128,3,3)),\n",
    "    maxpool3_pool_size=(2, 2),\n",
    "    dropout3_p=0.2,\n",
    "    \n",
    "    ## layer conv2d4\n",
    "    conv2d4_num_filters=512,\n",
    "    conv2d4_filter_size=(3, 3),\n",
    "    conv2d4_nonlinearity=lasagne.nonlinearities.rectify,  \n",
    "    conv2d4_W=np.concatenate(prev_mod['conv4'][0], axis=0).reshape((512,512,3,3)), \n",
    "    maxpool4_pool_size=(2, 2),\n",
    "    dropout4_p=0.2,    \n",
    "    \n",
    "    # dense fully connected layer 1\n",
    "    dense1_num_units=256,\n",
    "    dense1_nonlinearity=lasagne.nonlinearities.rectify,  \n",
    "    #dense1_W=np.concatenate(prev_mod['hidden4'][0], axis=0).reshape(512,256),   \n",
    "    dropout5_p=0.2,    \n",
    "    \n",
    "    # dense fully connected layer 2\n",
    "    dense2_num_units=512,\n",
    "    dense2_nonlinearity=lasagne.nonlinearities.rectify, \n",
    "    dense2_W=np.concatenate(prev_mod['hidden5'][0], axis=0).reshape(256,512),     \n",
    "    dropout6_p=0.2,    \n",
    "    \n",
    "    # output Layer\n",
    "    output_nonlinearity=lasagne.nonlinearities.softmax,\n",
    "    output_num_units=7,\n",
    "    \n",
    "    # optimization method params\n",
    "    update=nesterov_momentum,\n",
    "    #update_learning_rate=theano.shared(float32(0.05)),\n",
    "    #update_momentum=theano.shared(float32(0.9)),  \n",
    "    update_learning_rate = 0.005,\n",
    "    update_momentum = 0.9,   \n",
    "    max_epochs=100,\n",
    "    verbose=1,\n",
    "    )\n",
    "# Train the network\n",
    "deepFacialRecognition = net_fin.fit(x_train, y_train)\n",
    "\n",
    "import cPickle as pickle\n",
    "with open('.\\\\TrainedModels\\\\net_deep_aug_tran.pickle', 'wb') as f:\n",
    "    pickle.dump(net_fin, f, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
